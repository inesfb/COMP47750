{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic DTW Code\n",
    "Code from https://towardsdatascience.com/dynamic-time-warping-3933f25fcdd  \n",
    "This code implements a simple DTW measure between two series represented as lists.  \n",
    "It allows for series of different lengths and has a `window` parameter that determines the amount of warping allowed.  \n",
    "For series of different lengths, the minimum warping will be the difference in the lengths.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input two arrays and a warping metric, output distance between arrays\n",
    "def dtw(s, t, window):\n",
    "    n, m = len(s), len(t)\n",
    "    w = np.max([window, abs(n-m)]) # warping cannot be less than the difference in lengths. \n",
    "    dtw_matrix = np.zeros((n+1, m+1))\n",
    "    \n",
    "    for i in range(n+1):\n",
    "        for j in range(m+1):\n",
    "            dtw_matrix[i, j] = np.inf\n",
    "    dtw_matrix[0, 0] = 0\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(np.max([1, i-w]), np.min([m, i+w])+1):\n",
    "            dtw_matrix[i, j] = 0\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(np.max([1, i-w]), np.min([m, i+w])+1):\n",
    "            cost = abs(s[i-1] - t[j-1])\n",
    "            # take last min from a square box\n",
    "            last_min = np.min([dtw_matrix[i-1, j], dtw_matrix[i, j-1], dtw_matrix[i-1, j-1]])\n",
    "            dtw_matrix[i, j] = cost + last_min\n",
    "    return dtw_matrix[-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,3,5]\n",
    "b = [1,2,2,2,2,2,2,4]\n",
    "dtw(a,b, window = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [7,7,8,9,10,10,7,4,2,1,2,4,7,11,10,9,7]\n",
    "x2 = [7,8,10,10,8,7,3,2,2,4,6,12,12,9,7,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw_0 = dtw(x1,x2,window = 1)\n",
    "dtw_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works also for numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[7,7,8,9,10,10,7,4,2,1,2,4,7,11,10,9,7],\n",
    "                [7,8,10,10,8,7,3,2,2,4,6,12,12,9,7,7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  7,  8,  9, 10, 10,  7,  4,  2,  1,  2,  4,  7, 11, 10,  9,  7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 43.0\n",
      "1 19.0\n",
      "2 9.0\n",
      "3 9.0\n",
      "4 9.0\n",
      "5 9.0\n",
      "6 9.0\n",
      "7 9.0\n",
      "8 9.0\n",
      "9 9.0\n"
     ]
    }
   ],
   "source": [
    "for w in range(10):\n",
    "    dtw_n = dtw(x[0],x[1],window = w)\n",
    "    print(w, dtw_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "#### 1. Use the DTW function in the notebook to implement a simple 1-NN classifier for time-series data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_classification(train_data_features, train_data_labels, test_row, window): \n",
    "    \n",
    "    test_row_list = test_row.values.flatten().tolist()\n",
    "    \n",
    "    distances = {}\n",
    "    \n",
    "    for row_num in train_data_features.index:\n",
    "        row = train_data_features.loc[row_num].values.flatten().tolist()\n",
    "        \n",
    "        dist = dtw(test_row_list, row, window)\n",
    "        distances[dist] = row_num\n",
    "        \n",
    "    nearest_neighbor = distances[min(distances.keys())]\n",
    "    \n",
    "    classification = train_data_labels.loc[nearest_neighbor]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Test the performance of this classifier on the dataset provided in the file UMD_TEST.txt. This is a three-class synthetic time-series dataset - see details here https://www.timeseriesclassification.com/description.php?Dataset=UMD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"UMD_TEST.txt\", sep=\"\\s+\", header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split test and train data\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[0]\n",
    "X = df[list(range(1,144))]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#holdout test\n",
    "window = 1\n",
    "results2 = []\n",
    "\n",
    "for example_index in X_test.index:\n",
    "    actual_label = y_test[example_index]\n",
    "    predicted_label = predicted_classification(X_train, y_train, X_test.loc[example_index], window)\n",
    "    results2.append(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray: 0.896551724137931\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = results2\n",
    "y_true = y_test\n",
    "score = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuray: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  1,  0],\n",
       "       [ 0, 11,  0],\n",
       "       [ 0,  2,  7]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model seems to perform fairly well at classifying the data into the three classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Given that the time-series are all the same length (150 ticks) Euclidean distance can also be used as distance metric. Compare the 1-NN DTW performance with 1-NN Euclidean. Use the scikit-learn implementation for the Euclidean model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set up euclidean knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "euclidean_1NN = KNeighborsClassifier(n_neighbors=1, metric=\"euclidean\")\n",
    "euclidean_1NN.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy:  0.7931034482758621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8, 1, 0],\n",
       "       [1, 9, 1],\n",
       "       [1, 2, 6]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = euclidean_1NN.predict(X_test)\n",
    "\n",
    "print(\"Acurracy: \", accuracy_score(y_true,y_pred))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1NN model with euclidean distance seems to perform worse than the 1NN model with dynamic time warping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Find the best value for the window parameter for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acurracy(window):\n",
    "    results = []\n",
    "\n",
    "    for example_index in X_test.index:\n",
    "        actual_label = y_test[example_index]\n",
    "        predicted_label = predicted_classification(X_train, y_train, X_test.loc[example_index], window)\n",
    "        results.append(predicted_label)\n",
    "        \n",
    "    y_pred = results\n",
    "    y_true = y_test\n",
    "    score = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0: 0.8275862068965517\n",
      "Accuracy of 2: 0.896551724137931\n",
      "Accuracy of 4: 0.9310344827586207\n",
      "Accuracy of 6: 0.9310344827586207\n",
      "Accuracy of 8: 0.9310344827586207\n"
     ]
    }
   ],
   "source": [
    "for window in range(0, 10, 2):\n",
    "    acc = get_acurracy(window)\n",
    "    print(\"Accuracy of {}: {}\".format(window, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9310344827586207"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acurracy(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy rises when increasing the window size between window=0 and window=4, but does not seem to improve further when increasing the size of the window beyond window=4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. The k-NN classifier in scikit-learn has a metric parameter that allows for user-defined distance metrics. Adapt the DTW code provided so that it can be incorporated  in a scikit-learn k-NN  classifier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_dtw(s, t):\n",
    "    \n",
    "    window = 1 #using this value that's the window parameter when running the original dtw in Tsk 1\n",
    "    \n",
    "    n, m = len(s), len(t)\n",
    "    w = np.max([window, abs(n-m)])  \n",
    "    dtw_matrix = np.zeros((n+1, m+1))\n",
    "    \n",
    "    for i in range(n+1):\n",
    "        for j in range(m+1):\n",
    "            dtw_matrix[i, j] = np.inf\n",
    "    dtw_matrix[0, 0] = 0\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(np.max([1, i-w]), np.min([m, i+w])+1):\n",
    "            dtw_matrix[i, j] = 0\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(np.max([1, i-w]), np.min([m, i+w])+1):\n",
    "            cost = abs(s[i-1] - t[j-1])\n",
    "            # take last min from a square box\n",
    "            last_min = np.min([dtw_matrix[i-1, j], dtw_matrix[i, j-1], dtw_matrix[i-1, j-1]])\n",
    "            dtw_matrix[i, j] = cost + last_min\n",
    "    return dtw_matrix[-1,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Test the performance of this classifier and compare with the 1-NN results from Task 1. Verify that the 1-NN results are consistent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy:  0.896551724137931\n"
     ]
    }
   ],
   "source": [
    "#verifying results at k=1 are the same\n",
    "window = 1\n",
    "dtw_kNN = KNeighborsClassifier(n_neighbors=1, metric=modified_dtw)\n",
    "dtw_kNN.fit(X_train,y_train)\n",
    "\n",
    "y_pred = dtw_kNN.predict(X_test)\n",
    "\n",
    "print(\"Acurracy: \", accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1NN using modified_dtw the same acurracy as when using the original dtw function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  1,  0],\n",
       "       [ 1, 10,  0],\n",
       "       [ 2,  4,  3]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy:  0.7931034482758621\n"
     ]
    }
   ],
   "source": [
    "#modified_dtw with even larger k\n",
    "dtw_kNN = KNeighborsClassifier(n_neighbors=10, metric=modified_dtw)\n",
    "dtw_kNN.fit(X_train,y_train)\n",
    "\n",
    "y_pred = dtw_kNN.predict(X_test)\n",
    "print(\"Acurracy: \", accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurracy seems to decrease as the number of neighbors increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compare with k-NN Euclidean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy:  0.7241379310344828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 8,  1,  0],\n",
       "       [ 1, 10,  0],\n",
       "       [ 2,  4,  3]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modified_dtw with k=4\n",
    "dtw_kNN = KNeighborsClassifier(n_neighbors=4, metric=modified_dtw)\n",
    "dtw_kNN.fit(X_train,y_train)\n",
    "\n",
    "y_pred = dtw_kNN.predict(X_test)\n",
    "print(\"Acurracy: \", accuracy_score(y_true,y_pred))\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy:  0.7241379310344828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 8,  1,  0],\n",
       "       [ 1, 10,  0],\n",
       "       [ 2,  4,  3]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#euclidean distance with k=4\n",
    "kNN = KNeighborsClassifier(n_neighbors=4, metric=\"euclidean\")\n",
    "kNN.fit(X_train,y_train)\n",
    "\n",
    "print(\"Acurracy: \", accuracy_score(y_true,y_pred))\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4NN using euclidean distance seems to perform about the same as 4NN using dynamic time warping."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
